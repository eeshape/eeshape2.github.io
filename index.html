<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>이도형 (Dohyeong Lee)</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            color: #333;
            line-height: 1.7;
            background-color: #fff;
        }

        a {
            color: #2563eb;
            text-decoration: none;
        }

        a:hover {
            text-decoration: underline;
        }

        .container {
            max-width: 960px;
            margin: 0 auto;
            padding: 40px 24px;
        }

        /* Profile */
        .profile {
            display: flex;
            gap: 40px;
            align-items: flex-start;
            margin-bottom: 48px;
        }

        .profile-photo {
            width: 180px;
            height: 180px;
            border-radius: 50%;
            background-color: #e5e7eb;
            flex-shrink: 0;
            display: flex;
            align-items: center;
            justify-content: center;
            overflow: hidden;
            margin-top: 0;
        }

        .profile-photo img {
            width: 100%;
            height: 100%;
            object-fit: cover;
            object-position: center 35%;
        }

        .profile-photo .placeholder {
            font-size: 14px;
            color: #9ca3af;
            text-align: center;
            padding: 10px;
        }

        .profile-info h1 {
            font-size: 28px;
            font-weight: 700;
            color: #111;
            margin-bottom: 4px;
        }

        .profile-info .name-en {
            font-size: 16px;
            color: #6b7280;
            margin-bottom: 12px;
        }

        .profile-info .affiliation {
            font-size: 15px;
            color: #4b5563;
            margin-bottom: 16px;
            line-height: 1.6;
        }

        .profile-links {
            display: flex;
            flex-wrap: wrap;
            gap: 12px;
            font-size: 14px;
        }

        .profile-links a {
            display: inline-flex;
            align-items: center;
            gap: 5px;
            color: #4b5563;
            padding: 4px 0;
        }

        .profile-links a:hover {
            color: #2563eb;
        }

        .profile-links .sep {
            color: #d1d5db;
        }

        /* Sections */
        section {
            margin-bottom: 40px;
        }

        section h2 {
            font-size: 20px;
            font-weight: 700;
            color: #111;
            margin-bottom: 16px;
            padding-bottom: 8px;
            border-bottom: 2px solid #e5e7eb;
        }

        section p {
            font-size: 15px;
            color: #374151;
        }

        /* Research Interests */
        .interests {
            display: flex;
            flex-wrap: wrap;
            gap: 8px;
            list-style: none;
        }

        .interests li {
            background: #f3f4f6;
            padding: 6px 14px;
            border-radius: 20px;
            font-size: 14px;
            color: #374151;
        }

        /* Publications */
        .pub-list {
            list-style: none;
        }

        .pub-list li {
            padding: 16px 0;
            border-bottom: 1px solid #f3f4f6;
        }

        .pub-list li:last-child {
            border-bottom: none;
        }

        .pub-title {
            font-size: 15px;
            font-weight: 600;
            color: #111;
            margin-bottom: 4px;
        }

        .pub-authors {
            font-size: 14px;
            color: #6b7280;
            margin-bottom: 2px;
        }

        .pub-venue {
            font-size: 14px;
            color: #6b7280;
            font-style: italic;
        }

        .pub-links {
            margin-top: 6px;
            font-size: 13px;
        }

        /* Paper Reading List */
        details {
            margin-bottom: 8px;
        }

        summary {
            font-size: 15px;
            font-weight: 600;
            color: #111;
            cursor: pointer;
            padding: 8px 0;
        }

        summary:hover {
            color: #2563eb;
        }

        .paper-reading-list {
            list-style: none;
            padding-left: 16px;
            margin: 4px 0 12px;
        }

        .paper-reading-list li {
            font-size: 14px;
            color: #6b7280;
            padding: 4px 0;
            border-bottom: 1px solid #f3f4f6;
        }

        .paper-reading-list li:last-child {
            border-bottom: none;
        }

        /* Item list (Education, Experience, etc.) */
        .item-list {
            list-style: none;
        }

        .item-list li {
            padding: 12px 0;
            display: flex;
            justify-content: space-between;
            align-items: baseline;
        }

        .item-list li + li {
            border-top: 1px solid #f3f4f6;
        }

        .item-title {
            font-size: 15px;
            font-weight: 600;
            color: #111;
        }

        .item-desc {
            font-size: 14px;
            color: #6b7280;
        }

        .item-year {
            font-size: 14px;
            color: #9ca3af;
            flex-shrink: 0;
            margin-left: 16px;
        }

        /* Footer */
        footer {
            margin-top: 48px;
            padding-top: 24px;
            border-top: 1px solid #e5e7eb;
            font-size: 13px;
            color: #9ca3af;
            text-align: center;
        }

        /* Responsive */
        @media (max-width: 640px) {
            .profile {
                flex-direction: column;
                align-items: center;
                text-align: center;
            }

            .profile-links {
                justify-content: center;
            }

            .item-list li {
                flex-direction: column;
                gap: 2px;
            }

            .item-year {
                margin-left: 0;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <!-- Profile -->
        <div class="profile">
            <div class="profile-photo">
                <img src="photo.jpg" alt="이도형">
            </div>
            <div class="profile-info">
                <h1>이도형</h1>
                <div class="name-en">Dohyeong Lee</div>
                <div class="affiliation">
                    인천대학교 정보통신공학과 4학년<br>
                    <a href="https://sites.google.com/view/trustlab-inu/home" target="_blank">Trustworthy AI Lab</a> 학부 연구생
                </div>
                <div class="profile-links">
                    <a href="mailto:eeshape@inu.ac.kr">Email</a>
                    <span class="sep">|</span>
                    <a href="https://github.com/eeshape" target="_blank">GitHub</a>
                    <span class="sep">|</span>
                    <a href="https://scholar.google.com/" target="_blank">Google Scholar</a>
                    <span class="sep">|</span>
                    <a href="/cv.pdf" target="_blank">CV</a>
                </div>
            </div>
        </div>

        <!-- 소개 -->
        <section>
            <h2>소개</h2>
            <p>
                인천대학교 정보통신공학과 4학년에 재학 중이며,
                <strong>컴퓨터 비전(Computer Vision)</strong> 분야를 연구하고 있습니다.
                주로 배포된 딥러닝 모델에서의 <strong>공정성(Fairness)</strong> 문제와
                <strong>적대적 공격(Adversarial Attack)</strong> 및 <strong>적대적 섭동(Adversarial Perturbation)</strong>을 활용한 편향 완화 기법에 관심을 두고 있습니다.
            </p>
            <p style="margin-top: 12px;">
                <strong>IPIU 2026</strong>에서 포스터 발표를 마쳤으며, 현재 <strong>CVPR 2026 Workshop</strong> 논문 제출을 목표로
                연구를 진행하고 있습니다. 연구 외에도 교내 <strong>GDSC(Google Developer Student Clubs)</strong> 챕터를
                직접 창립하고 3년 연속 Lead를 맡아 개발자 커뮤니티를 운영해 왔습니다.
            </p>
        </section>

        <!-- 연구 관심 분야 -->
        <section>
            <h2>연구 관심 분야</h2>
            <ul class="interests">
                <li>Computer Vision</li>
                <li>Object Detection</li>
                <li>Fairness in AI</li>
                <li>Adversarial Attack</li>
                <li>Adversarial Perturbation</li>
                <li>Deep Learning</li>
            </ul>
        </section>

        <!-- 논문 -->
        <section>
            <h2>논문</h2>
            <ul class="pub-list">
                <li>
                    <div class="pub-title">배포된 객체 탐지 모델에서 입력 섭동을 이용한 공정성 개선 기법</div>
                    <div class="pub-authors"><u>이도형</u>*, 최서연*, 박성호&dagger;</div>
                    <div class="pub-venue">IPIU 2026 (제38회 영상처리 및 이해에 관한 워크샵), 2026년 2월 | 포스터 발표</div>
                    <div class="pub-links">
                        <span style="font-size:12px; color:#9ca3af;">* 공동 제1저자 &nbsp; &dagger; 교신저자</span>
                    </div>
                </li>
            </ul>
        </section>

        <!-- 읽은 논문 -->
        <section>
            <h2>읽은 논문</h2>
            <details>
                <summary>발표 세미나 (논문 리뷰 발표자료)</summary>
                <ul class="paper-reading-list">
                    <li><a href="seminars/faster-rcnn.pdf" target="_blank">Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks</a> <span style="font-size:12px; color:#9ca3af;">2025.01</span></li>
                    <li><a href="seminars/show-attend-tell.pdf" target="_blank">Show, Attend and Tell: Neural Image Caption Generation with Visual Attention</a> <span style="font-size:12px; color:#9ca3af;">2025.03</span></li>
                    <li><a href="seminars/detr.pdf" target="_blank">DETR: End-to-End Object Detection with Transformers</a> <span style="font-size:12px; color:#9ca3af;">2025.05</span></li>
                    <li><a href="seminars/vit.pdf" target="_blank">ViT: An Image is Worth 16x16 Words</a> <span style="font-size:12px; color:#9ca3af;">2025.05</span></li>
                    <li><a href="seminars/lami-detr.pdf" target="_blank">LaMI-DETR: Open-Vocabulary Detection with Language Model Instruction</a> <span style="font-size:12px; color:#9ca3af;">2025.05</span></li>
                    <li><a href="seminars/fairness-ad.pdf" target="_blank">Fairness in Autonomous Driving</a> <span style="font-size:12px; color:#9ca3af;">2025.06</span></li>
                    <li><a href="seminars/balanced-datasets.pdf" target="_blank">Balanced Datasets Are Not Enough: Estimating and Mitigating Gender Bias in Deep Image Representations</a> <span style="font-size:12px; color:#9ca3af;">2025.08</span></li>
                    <li><a href="seminars/adversarial-attention.pdf" target="_blank">Adversarial Attention Perturbations for Large Object Detection Transformers</a> <span style="font-size:12px; color:#9ca3af;">2025.09</span></li>
                    <li><a href="seminars/iap.pdf" target="_blank">IAP: Instance-Aware Predictive Navigation in Multi-Agent Environments</a> <span style="font-size:12px; color:#9ca3af;">2025.11</span></li>
                    <li><a href="seminars/dino.pdf" target="_blank">DINO: Emerging Properties in Self-Supervised Vision Transformers</a> <span style="font-size:12px; color:#9ca3af;">2026.01</span></li>
                </ul>
            </details>
            <details>
                <summary>Fairness & Adversarial Perturbation</summary>
                <ul class="paper-reading-list">
                    <li>Fairness-aware Adversarial Perturbation Towards Bias Mitigation for Deployed Deep Models (FAAP)</li>
                    <li>Balanced Datasets Are Not Enough: Estimating and Mitigating Gender Bias in Deep Image Representations</li>
                    <li>Fair Contrastive Learning for Facial Attribute Classification</li>
                    <li>FD-VAE: Learning Disentangled Representation for Fair Facial Attribute Classification via Fairness-aware Information Alignment</li>
                    <li>Fairness in Autonomous Driving</li>
                    <li>AdvFaces: Adversarial Face Synthesis</li>
                </ul>
            </details>
            <details>
                <summary>Adversarial Attack & Object Detection</summary>
                <ul class="paper-reading-list">
                    <li>Adversarial Machine Learning at Scale</li>
                    <li>Robust Physical Adversarial Attack on Faster R-CNN Object Detection</li>
                    <li>Making an Invisibility Cloak: Real-World Adversarial Attacks on Object Detectors</li>
                    <li>Transferable Adversarial Attacks for Object Detection</li>
                    <li>Adversarial Attention Perturbations for Large Object Detection Transformers</li>
                </ul>
            </details>
            <details>
                <summary>Object Detection</summary>
                <ul class="paper-reading-list">
                    <li>DETR: End-to-End Object Detection with Transformers</li>
                    <li>LaMI-DETR: Open-Vocabulary Detection with Language Model Instruction</li>
                    <li>RT-DETR: DETRs Beat YOLOs on Real-time Object Detection</li>
                    <li>Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks</li>
                    <li>IAP: Instance-Aware Predictive Navigation in Multi-Agent Environments</li>
                </ul>
            </details>
            <details>
                <summary>Generative Models</summary>
                <ul class="paper-reading-list">
                    <li>Denoising Diffusion Probabilistic Models (DDPM)</li>
                    <li>Stable Diffusion: High-Resolution Image Synthesis with Latent Diffusion Models</li>
                    <li>Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks (CycleGAN)</li>
                    <li>Wasserstein GAN (WGAN)</li>
                </ul>
            </details>
            <details>
                <summary>Representation Learning & Vision</summary>
                <ul class="paper-reading-list">
                    <li>An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale (ViT)</li>
                    <li>Attention Is All You Need</li>
                    <li>DINO: Emerging Properties in Self-Supervised Vision Transformers</li>
                    <li>A Simple Framework for Contrastive Learning of Visual Representations (SimCLR)</li>
                    <li>Supervised Contrastive Learning</li>
                    <li>Momentum Contrast for Unsupervised Visual Representation Learning (MoCo)</li>
                    <li>Show, Attend and Tell: Neural Image Caption Generation with Visual Attention</li>
                </ul>
            </details>
            <details>
                <summary>Dataset & Benchmark</summary>
                <ul class="paper-reading-list">
                    <li>FACET: Fairness in Computer Vision Evaluation Benchmark</li>
                </ul>
            </details>
        </section>

        <!-- 학력 -->
        <section>
            <h2>학력</h2>
            <ul class="item-list">
                <li>
                    <div>
                        <div class="item-title"><a href="https://www.inu.ac.kr" target="_blank">인천대학교</a> 정보통신공학과</div>
                        <div class="item-desc">학사 과정 (4학년 재학 중)</div>
                    </div>
                    <div class="item-year">2021 &ndash; 현재</div>
                </li>
                <li>
                    <div>
                        <div class="item-title"><a href="http://dimigo.hs.kr/" target="_blank">한국디지털미디어고등학교</a></div>
                        <div class="item-desc">e-Business학과</div>
                    </div>
                    <div class="item-year">2017 &ndash; 2020</div>
                </li>
            </ul>
        </section>

        <!-- 경력 및 활동 -->
        <section>
            <h2>경력 및 활동</h2>
            <ul class="item-list">
                <li>
                    <div>
                        <div class="item-title"><a href="https://sites.google.com/view/trustlab-inu/home" target="_blank">Trustworthy AI Lab</a>, 인천대학교 &mdash; 학부 연구생</div>
                        <div class="item-desc">객체 탐지 공정성 연구 수행.<br>IPIU 2026 포스터 발표.<br>CVPR 2026 Workshop 준비.</div>
                    </div>
                    <div class="item-year">2024.09 &ndash; 현재</div>
                </li>
                <li>
                    <div>
                        <div class="item-title">GDSC / GDGoC 인천대학교 &mdash; Founder & Lead</div>
                        <div class="item-desc">교내 GDSC 챕터를 최초 창립하고 3년 연속 Lead 역임.<br>주간 AI 세미나 운영, 500명 규모 컨퍼런스 및 <a href="https://developers.google.com/community/gdsc-solution-challenge" target="_blank">Solution Challenge</a> 준비 해커톤 3회 이상 총괄.<br>Google 공식 <a href="certificate.pdf" target="_blank">Certificate of Participation</a> 수료.</div>
                    </div>
                    <div class="item-year">2024 &ndash; 현재</div>
                </li>
            </ul>
        </section>

        <!-- 발표 -->
        <section>
            <h2>발표</h2>
            <ul class="item-list">
                <li>
                    <div>
                        <div class="item-title"><a href="poster.pdf" target="_blank">포스터 : 배포된 객체 탐지 모델에서 입력 섭동을 이용한 공정성 개선 기법</a></div>
                        <div class="item-desc">IPIU 2026 (제38회 영상처리 및 이해에 관한 워크샵), 제주</div>
                    </div>
                    <div class="item-year">2026.02</div>
                </li>
                <li>
                    <div>
                        <div class="item-title"><a href="https://gdg.community.dev/events/details/google-gdg-on-campus-kookmin-university-seoul-south-korea-presents-build-with-aipre-solution-challenge/" target="_blank">대표 연사 및 운영진</a> : Gemini API를 활용한 <a href="https://developers.google.com/community/gdsc-solution-challenge" target="_blank">Solution Challenge</a> 해커톤 준비</div>
                        <div class="item-desc"><a href="https://sites.google.com/view/gdeveloperskorea/gdg/build-with-ai-2025" target="_blank">Build with AI</a>, 9개 대학 연합 행사 (약 100명 참가).<br>핸즈온 세션 연사 및 운영진.</div>
                    </div>
                    <div class="item-year">2025.05.03</div>
                </li>
            </ul>
        </section>

        <!-- 장학 -->
        <section>
            <h2>장학</h2>
            <ul class="item-list">
                <li>
                    <div>
                        <div class="item-title"><a href="scholarship.pdf" target="_blank">장학금 수혜확인서</a></div>
                        <div class="item-desc">인천대학교 장학금 수혜 내역</div>
                    </div>
                </li>
            </ul>
        </section>

        <footer>
            &copy; 2026 이도형. 최종 업데이트: 2026년 2월.
        </footer>
    </div>
</body>
</html>
