<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>이도형 (Dohyeong Lee)</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            color: #333;
            line-height: 1.7;
            background-color: #fff;
        }

        a {
            color: #2563eb;
            text-decoration: none;
        }

        a:hover {
            text-decoration: underline;
        }

        .container {
            max-width: 960px;
            margin: 0 auto;
            padding: 40px 24px;
        }

        /* Profile */
        .profile {
            display: flex;
            gap: 40px;
            align-items: flex-start;
            margin-bottom: 48px;
        }

        .profile-photo {
            width: 180px;
            height: 180px;
            border-radius: 50%;
            background-color: #e5e7eb;
            flex-shrink: 0;
            display: flex;
            align-items: center;
            justify-content: center;
            overflow: hidden;
            margin-top: 0;
        }

        .profile-photo img {
            width: 100%;
            height: 100%;
            object-fit: cover;
            object-position: center 35%;
        }

        .profile-photo .placeholder {
            font-size: 14px;
            color: #9ca3af;
            text-align: center;
            padding: 10px;
        }

        .profile-info h1 {
            font-size: 28px;
            font-weight: 700;
            color: #111;
            margin-bottom: 4px;
        }

        .profile-info .name-en {
            font-size: 16px;
            color: #6b7280;
            margin-bottom: 12px;
        }

        .profile-info .affiliation {
            font-size: 15px;
            color: #4b5563;
            margin-bottom: 16px;
            line-height: 1.6;
        }

        .profile-links {
            display: flex;
            flex-wrap: wrap;
            gap: 12px;
            font-size: 14px;
        }

        .profile-links a {
            display: inline-flex;
            align-items: center;
            gap: 5px;
            color: #4b5563;
            padding: 4px 0;
        }

        .profile-links a:hover {
            color: #2563eb;
        }

        .profile-links .sep {
            color: #d1d5db;
        }

        /* Sections */
        section {
            margin-bottom: 40px;
        }

        section h2 {
            font-size: 20px;
            font-weight: 700;
            color: #111;
            margin-bottom: 16px;
            padding-bottom: 8px;
            border-bottom: 2px solid #e5e7eb;
        }

        section p {
            font-size: 15px;
            color: #374151;
        }

        /* Research Interests */
        .interests {
            display: flex;
            flex-wrap: wrap;
            gap: 8px;
            list-style: none;
        }

        .interests li {
            background: #f3f4f6;
            padding: 6px 14px;
            border-radius: 20px;
            font-size: 14px;
            color: #374151;
        }

        /* Publications */
        .pub-list {
            list-style: none;
        }

        .pub-list li {
            padding: 16px 0;
            border-bottom: 1px solid #f3f4f6;
        }

        .pub-list li:last-child {
            border-bottom: none;
        }

        .pub-title {
            font-size: 15px;
            font-weight: 600;
            color: #111;
            margin-bottom: 4px;
        }

        .pub-authors {
            font-size: 14px;
            color: #6b7280;
            margin-bottom: 2px;
        }

        .pub-venue {
            font-size: 14px;
            color: #6b7280;
            font-style: italic;
        }

        .pub-links {
            margin-top: 6px;
            font-size: 13px;
        }

        /* Paper Reading List */
        details {
            margin-bottom: 8px;
        }

        summary {
            font-size: 15px;
            font-weight: 600;
            color: #111;
            cursor: pointer;
            padding: 8px 0;
        }

        summary:hover {
            color: #2563eb;
        }

        .paper-reading-list {
            list-style: none;
            padding-left: 16px;
            margin: 4px 0 12px;
        }

        .paper-reading-list li {
            font-size: 14px;
            color: #6b7280;
            padding: 4px 0;
            border-bottom: 1px solid #f3f4f6;
        }

        .paper-reading-list li:last-child {
            border-bottom: none;
        }

        /* Item list (Education, Experience, etc.) */
        .item-list {
            list-style: none;
        }

        .item-list li {
            padding: 12px 0;
            display: flex;
            justify-content: space-between;
            align-items: baseline;
        }

        .item-list li + li {
            border-top: 1px solid #f3f4f6;
        }

        .item-title {
            font-size: 15px;
            font-weight: 600;
            color: #111;
        }

        .item-desc {
            font-size: 14px;
            color: #6b7280;
        }

        .item-year {
            font-size: 14px;
            color: #9ca3af;
            flex-shrink: 0;
            margin-left: 16px;
        }

        /* Footer */
        footer {
            margin-top: 48px;
            padding-top: 24px;
            border-top: 1px solid #e5e7eb;
            font-size: 13px;
            color: #9ca3af;
            text-align: center;
        }

        /* Responsive */
        @media (max-width: 640px) {
            .profile {
                flex-direction: column;
                align-items: center;
                text-align: center;
            }

            .profile-links {
                justify-content: center;
            }

            .item-list li {
                flex-direction: column;
                gap: 2px;
            }

            .item-year {
                margin-left: 0;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <!-- Profile -->
        <div class="profile">
            <div class="profile-photo">
                <img src="photo.jpg" alt="이도형">
            </div>
            <div class="profile-info">
                <h1>이도형</h1>
                <div class="name-en">Dohyeong Lee</div>
                <div class="affiliation">
                    인천대학교 정보통신공학과 4학년<br>
                    <a href="https://sites.google.com/view/trustlab-inu/home" target="_blank">Trustworthy AI Lab</a> 학부 연구생 (지도교수 : <a href="https://sites.google.com/view/trustlab-inu/members?authuser=0" target="_blank">박성호</a>)
                </div>
                <div class="profile-links">
                    <a href="mailto:eeshape@inu.ac.kr">Email</a>
                    <span class="sep">|</span>
                    <a href="https://github.com/eeshape" target="_blank">GitHub</a>
                </div>
            </div>
        </div>

        <!-- 소개 -->
        <section>
            <h2>소개</h2>
            <p>
                인천대학교 정보통신공학과 4학년에 재학 중이며,
                <strong>컴퓨터 비전(Computer Vision)</strong> 분야를 연구하고 있습니다.<br><br>
                주로 배포된 딥러닝 모델에서의 <strong>공정성(Fairness)</strong> 문제와
                <strong>적대적 공격(Adversarial Attack)</strong> 및 <strong>적대적 섭동(Adversarial Perturbation)</strong>을 활용한 편향 완화 기법에 관심을 두고 있습니다.<br>
                구체적으로, 이미 배포된 객체 탐지 모델을 재학습 없이 입력 이미지에 미세한 섭동을 가하여<br>
                성별·인종 등 인구통계학적 집단(demographic group) 간 탐지 성능 격차를 줄이는 공정성 개선 기법을 연구하고 있습니다.<br><br>
                <strong>IPIU 2026</strong>에서 포스터 발표를 마쳤으며, 현재 이를 확장한 후속 연구를 진행 중입니다.<br>
                연구 외에도 교내 <strong>GDSC(Google Developer Student Clubs)</strong> 챕터를
                직접 창립하고 2년 연속 Lead를 맡아 개발자 커뮤니티를 운영해 왔습니다.
            </p>
        </section>

        <!-- 연구 관심 분야 -->
        <section>
            <h2>연구 관심 분야</h2>
            <ul class="interests">
                <li>Computer Vision</li>
                <li>Object Detection</li>
                <li>Fairness in AI</li>
                <li>Adversarial Attack</li>
                <li>Adversarial Perturbation</li>
                <li>AI Safety</li>
                <li>Trustworthy AI</li>
                <li>Robustness</li>
                <li>Deep Learning</li>
            </ul>
        </section>

        <!-- 논문 -->
        <section>
            <h2>논문</h2>
            <ul class="pub-list">
                <li>
                    <div class="pub-title">배포된 객체 탐지 모델에서 입력 섭동을 이용한 공정성 개선 기법</div>
                    <div class="pub-authors"><u>이도형</u>*, 최서연*, 박성호&dagger;</div>
                    <div class="pub-venue">IPIU 2026 (제38회 영상처리 및 이해에 관한 워크샵), 2026년 2월 | 포스터 발표</div>
                    <div class="pub-links">
                        <span style="font-size:12px; color:#9ca3af;">* 공동 제1저자 &nbsp; &dagger; 교신저자</span>
                        &nbsp; <a href="poster.pdf" target="_blank">[Poster]</a>
                    </div>
                </li>
            </ul>
        </section>

        <!-- 읽은 논문 -->
        <section>
            <h2>읽은 논문</h2>
            <details>
                <summary>세미나 발표 (논문 리뷰 발표자료)</summary>
                <ul class="paper-reading-list">
                    <li><a href="seminars/faster-rcnn.pdf" target="_blank">Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks</a> <span style="font-size:12px; color:#9ca3af;">(NeurIPS 2015) · 2025.01</span></li>
                    <li><a href="seminars/show-attend-tell.pdf" target="_blank">Show, Attend and Tell: Neural Image Caption Generation with Visual Attention</a> <span style="font-size:12px; color:#9ca3af;">(ICML 2015) · 2025.03</span></li>
                    <li><a href="seminars/detr.pdf" target="_blank">DETR: End-to-End Object Detection with Transformers</a> <span style="font-size:12px; color:#9ca3af;">(ECCV 2020) · 2025.05</span></li>
                    <li><a href="seminars/vit.pdf" target="_blank">ViT: An Image is Worth 16x16 Words</a> <span style="font-size:12px; color:#9ca3af;">(ICLR 2021) · 2025.05</span></li>
                    <li><a href="seminars/lami-detr.pdf" target="_blank">LaMI-DETR: Open-Vocabulary Detection with Language Model Instruction</a> <span style="font-size:12px; color:#9ca3af;">(ECCV 2024) · 2025.05</span></li>
                    <li><a href="seminars/fairness-ad.pdf" target="_blank">Fairness in Autonomous Driving</a> <span style="font-size:12px; color:#9ca3af;">(arXiv 2024) · 2025.06</span></li>
                    <li><a href="seminars/balanced-datasets.pdf" target="_blank">Balanced Datasets Are Not Enough: Estimating and Mitigating Gender Bias in Deep Image Representations</a> <span style="font-size:12px; color:#9ca3af;">(ICCV 2019) · 2025.08</span></li>
                    <li><a href="seminars/adversarial-attention.pdf" target="_blank">Adversarial Attention Perturbations for Large Object Detection Transformers</a> <span style="font-size:12px; color:#9ca3af;">(ICCV 2025) · 2025.09</span></li>
                    <li><a href="seminars/iap.pdf" target="_blank">IAP: Instance-Aware Predictive Navigation in Multi-Agent Environments</a> <span style="font-size:12px; color:#9ca3af;">(ICRA 2021) · 2025.11</span></li>
                    <li><a href="seminars/dino.pdf" target="_blank">DINO: Emerging Properties in Self-Supervised Vision Transformers</a> <span style="font-size:12px; color:#9ca3af;">(ICCV 2021) · 2026.01</span></li>
                </ul>
            </details>
            <details>
                <summary>Fairness & Adversarial Perturbation</summary>
                <ul class="paper-reading-list">
                    <li><a href="https://arxiv.org/abs/2203.01584" target="_blank">Fairness-aware Adversarial Perturbation Towards Bias Mitigation for Deployed Deep Models (FAAP)</a> <span style="font-size:12px; color:#9ca3af;">(CVPR 2022)</span></li>
                    <li><a href="https://arxiv.org/abs/1811.08489" target="_blank">Balanced Datasets Are Not Enough: Estimating and Mitigating Gender Bias in Deep Image Representations</a> <span style="font-size:12px; color:#9ca3af;">(ICCV 2019)</span></li>
                    <li><a href="https://arxiv.org/abs/2203.16209" target="_blank">Fair Contrastive Learning for Facial Attribute Classification</a> <span style="font-size:12px; color:#9ca3af;">(CVPR 2022)</span></li>
                    <li><a href="https://ojs.aaai.org/index.php/AAAI/article/view/16341" target="_blank">FD-VAE: Learning Disentangled Representation for Fair Facial Attribute Classification via Fairness-aware Information Alignment</a> <span style="font-size:12px; color:#9ca3af;">(AAAI 2021)</span></li>
                    <li><a href="https://arxiv.org/abs/2406.00219" target="_blank">Fairness in Autonomous Driving</a> <span style="font-size:12px; color:#9ca3af;">(arXiv 2024)</span></li>
                    <li><a href="https://arxiv.org/abs/1908.05449" target="_blank">AdvFaces: Adversarial Face Synthesis</a> <span style="font-size:12px; color:#9ca3af;">(IJCB 2020)</span></li>
                </ul>
            </details>
            <details>
                <summary>Adversarial Attack & Object Detection</summary>
                <ul class="paper-reading-list">
                    <li><a href="https://arxiv.org/abs/1611.01236" target="_blank">Adversarial Machine Learning at Scale</a> <span style="font-size:12px; color:#9ca3af;">(ICLR 2017)</span></li>
                    <li><a href="https://arxiv.org/abs/1804.05810" target="_blank">Robust Physical Adversarial Attack on Faster R-CNN Object Detection</a> <span style="font-size:12px; color:#9ca3af;">(ECML-PKDD 2018)</span></li>
                    <li><a href="https://arxiv.org/abs/1910.14667" target="_blank">Making an Invisibility Cloak: Real-World Adversarial Attacks on Object Detectors</a> <span style="font-size:12px; color:#9ca3af;">(ECCV 2020)</span></li>
                    <li><a href="https://arxiv.org/abs/1811.12641" target="_blank">Transferable Adversarial Attacks for Object Detection</a> <span style="font-size:12px; color:#9ca3af;">(IJCAI 2019)</span></li>
                    <li><a href="https://arxiv.org/abs/2508.02987" target="_blank">Adversarial Attention Perturbations for Large Object Detection Transformers</a> <span style="font-size:12px; color:#9ca3af;">(ICCV 2025)</span></li>
                </ul>
            </details>
            <details>
                <summary>Object Detection</summary>
                <ul class="paper-reading-list">
                    <li><a href="https://arxiv.org/abs/2005.12872" target="_blank">DETR: End-to-End Object Detection with Transformers</a> <span style="font-size:12px; color:#9ca3af;">(ECCV 2020)</span></li>
                    <li><a href="https://arxiv.org/abs/2407.11335" target="_blank">LaMI-DETR: Open-Vocabulary Detection with Language Model Instruction</a> <span style="font-size:12px; color:#9ca3af;">(ECCV 2024)</span></li>
                    <li><a href="https://arxiv.org/abs/2304.08069" target="_blank">RT-DETR: DETRs Beat YOLOs on Real-time Object Detection</a> <span style="font-size:12px; color:#9ca3af;">(CVPR 2024)</span></li>
                    <li><a href="https://arxiv.org/abs/1506.01497" target="_blank">Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks</a> <span style="font-size:12px; color:#9ca3af;">(NeurIPS 2015)</span></li>
                    <li><a href="https://arxiv.org/abs/2101.05893" target="_blank">IAP: Instance-Aware Predictive Navigation in Multi-Agent Environments</a> <span style="font-size:12px; color:#9ca3af;">(ICRA 2021)</span></li>
                </ul>
            </details>
            <details>
                <summary>Generative Models</summary>
                <ul class="paper-reading-list">
                    <li><a href="https://arxiv.org/abs/2006.11239" target="_blank">Denoising Diffusion Probabilistic Models (DDPM)</a> <span style="font-size:12px; color:#9ca3af;">(NeurIPS 2020)</span></li>
                    <li><a href="https://arxiv.org/abs/2112.10752" target="_blank">Stable Diffusion: High-Resolution Image Synthesis with Latent Diffusion Models</a> <span style="font-size:12px; color:#9ca3af;">(CVPR 2022)</span></li>
                    <li><a href="https://arxiv.org/abs/1703.10593" target="_blank">Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks (CycleGAN)</a> <span style="font-size:12px; color:#9ca3af;">(ICCV 2017)</span></li>
                    <li><a href="https://arxiv.org/abs/1701.07875" target="_blank">Wasserstein GAN (WGAN)</a> <span style="font-size:12px; color:#9ca3af;">(ICML 2017)</span></li>
                </ul>
            </details>
            <details>
                <summary>Representation Learning & Vision</summary>
                <ul class="paper-reading-list">
                    <li><a href="https://arxiv.org/abs/2010.11929" target="_blank">An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale (ViT)</a> <span style="font-size:12px; color:#9ca3af;">(ICLR 2021)</span></li>
                    <li><a href="https://arxiv.org/abs/1706.03762" target="_blank">Attention Is All You Need</a> <span style="font-size:12px; color:#9ca3af;">(NeurIPS 2017)</span></li>
                    <li><a href="https://arxiv.org/abs/2104.14294" target="_blank">DINO: Emerging Properties in Self-Supervised Vision Transformers</a> <span style="font-size:12px; color:#9ca3af;">(ICCV 2021)</span></li>
                    <li><a href="https://arxiv.org/abs/2002.05709" target="_blank">A Simple Framework for Contrastive Learning of Visual Representations (SimCLR)</a> <span style="font-size:12px; color:#9ca3af;">(ICML 2020)</span></li>
                    <li><a href="https://arxiv.org/abs/2004.11362" target="_blank">Supervised Contrastive Learning</a> <span style="font-size:12px; color:#9ca3af;">(NeurIPS 2020)</span></li>
                    <li><a href="https://arxiv.org/abs/1911.05722" target="_blank">Momentum Contrast for Unsupervised Visual Representation Learning (MoCo)</a> <span style="font-size:12px; color:#9ca3af;">(CVPR 2020)</span></li>
                    <li><a href="https://arxiv.org/abs/1502.03044" target="_blank">Show, Attend and Tell: Neural Image Caption Generation with Visual Attention</a> <span style="font-size:12px; color:#9ca3af;">(ICML 2015)</span></li>
                </ul>
            </details>
            <details>
                <summary>Dataset & Benchmark</summary>
                <ul class="paper-reading-list">
                    <li><a href="https://arxiv.org/abs/2309.00035" target="_blank">FACET: Fairness in Computer Vision Evaluation Benchmark</a> <span style="font-size:12px; color:#9ca3af;">(ICCV 2023)</span></li>
                </ul>
            </details>
        </section>

        <!-- 학력 -->
        <section>
            <h2>학력</h2>
            <ul class="item-list">
                <li>
                    <div>
                        <div class="item-title"><a href="https://www.inu.ac.kr" target="_blank">인천대학교</a> 정보통신공학과</div>
                        <div class="item-desc">학사 과정 (4학년 재학 중)<br>메카트로닉스공학과 입학 → 정보통신공학과 전과 (3학년 2학기, 2025.03)</div>
                    </div>
                    <div class="item-year">2021 &ndash; 현재</div>
                </li>
                <li>
                    <div>
                        <div class="item-title"><a href="http://dimigo.hs.kr/" target="_blank">한국디지털미디어고등학교</a></div>
                        <div class="item-desc">e-Business학과</div>
                    </div>
                    <div class="item-year">2017 &ndash; 2020</div>
                </li>
            </ul>
        </section>

        <!-- 경력 및 활동 -->
        <section>
            <h2>경력 및 활동</h2>
            <ul class="item-list">
                <li>
                    <div>
                        <div class="item-title"><a href="https://sites.google.com/view/trustlab-inu/home" target="_blank">Trustworthy AI Lab</a>, 인천대학교 &mdash; 학부 연구생 (1기, 초기 랩 멤버)</div>
                        <div class="item-desc">연구실 초기 세팅 단계부터 참여.<br>객체 탐지 공정성 연구 수행.<br>IPIU 2026 포스터 발표.<br>CVPR 2026 Workshop 준비.</div>
                    </div>
                    <div class="item-year">2024.09 &ndash; 현재</div>
                </li>
                <li>
                    <div>
                        <div class="item-title">GDSC / GDGoC 인천대학교 &mdash; Founder & Lead</div>
                        <div class="item-desc">교내 GDSC 챕터를 최초 창립하고 2년 연속 Lead 역임.<br><a href="https://github.com/GDG-INU/gdg-inu-seminar" target="_blank">월간 AI 세미나</a> 운영, 500명 규모 컨퍼런스 및 <a href="https://developers.google.com/community/gdsc-solution-challenge" target="_blank">Solution Challenge</a> 준비 해커톤 3회 이상 총괄.<br>Google 공식 <a href="certificate.pdf" target="_blank">Certificate of Participation</a> 수료.</div>
                    </div>
                    <div class="item-year">2024 &ndash; 현재</div>
                </li>
                <li>
                    <div>
                        <div class="item-title">심층학습 TA (Teaching Assistant)</div>
                        <div class="item-desc">심층학습 과목 수업 조교</div>
                    </div>
                    <div class="item-year">2025 2학기</div>
                </li>
            </ul>
        </section>

        <!-- 발표 -->
        <section>
            <h2>발표</h2>
            <ul class="item-list">
                <li>
                    <div>
                        <div class="item-title"><a href="https://gdg.community.dev/events/details/google-gdg-on-campus-kookmin-university-seoul-south-korea-presents-build-with-aipre-solution-challenge/" target="_blank">대표 연사 및 운영진</a> : Gemini API를 활용한 <a href="https://developers.google.com/community/gdsc-solution-challenge" target="_blank">Solution Challenge</a> 해커톤 준비</div>
                        <div class="item-desc"><a href="https://sites.google.com/view/gdeveloperskorea/gdg/build-with-ai-2025" target="_blank">Build with AI</a>, 8개 대학 연합 행사 (약 100명 참가).<br>핸즈온 세션 대표 연사 및 운영진.<br>국민대 · 연세대 · 고려대 · 삼육대 · 인천대 · 서울여대 · 한국외대 · 이화여대.<br>구글 스타트업 캠퍼스 (서울, 오토웨이 타워).</div>
                    </div>
                    <div class="item-year">2025.05.03</div>
                </li>
            </ul>
        </section>

        <!-- 프로젝트 -->
        <section>
            <h2>프로젝트</h2>
            <ul class="item-list">
                <li>
                    <div>
                        <div class="item-title"><a href="https://gdg.community.dev/events/details/google-gdg-on-campus-kangnam-university-yongin-south-korea-presents-2026-gdgoc-yeonhabhaekeoton-one-wave-haekeoton-teuggang/" target="_blank">GDGoC 연합 해커톤 'ONE WAVE'</a> &mdash; 운영진</div>
                        <div class="item-desc">GDGoC 연합 해커톤, 35팀 참가.<br>동국대학교, 1박 2일 해커톤.<br><a href="https://www.instagram.com/onewave.gdgoc/" target="_blank">Instagram</a></div>
                    </div>
                    <div class="item-year">2026.02</div>
                </li>
                <li>
                    <div>
                        <div class="item-title"><a href="https://gdg.community.dev/events/details/google-gdg-on-campus-kookmin-university-seoul-south-korea-presents-2025-gdgoc-new-year-hackathon-baegya/" target="_blank">GDGoC 연합 해커톤 '백야'</a> &mdash; 운영진</div>
                        <div class="item-desc">20개 대학 연합, 156명 참가 (25팀).<br>건국대학교 학생회관, 1박 2일 해커톤.<br><a href="https://yozm.wishket.com/magazine/detail/2974/" target="_blank">행사 후기 (요즘IT)</a> · <a href="https://youtu.be/qdphrX0sSwc" target="_blank">영상</a> · <a href="https://www.instagram.com/baekya.gdgoc/" target="_blank">Instagram</a></div>
                    </div>
                    <div class="item-year">2025.01</div>
                </li>
                <li>
                    <div>
                        <div class="item-title">착한지식 사회공헌 프로젝트 (교내 해커톤) &mdash; 대표</div>
                        <div class="item-desc">인천대학교 사회봉사센터 주관 공모전.<br>지역사회 문제 해결을 위한 지식·기술 활용 프로젝트 기획 및 총괄 운영.<br><a href="social-contribution.pdf" target="_blank">수료증</a></div>
                    </div>
                    <div class="item-year">2025</div>
                </li>
            </ul>
            <details>
                <summary>착한지식 상세 내용</summary>
                <ul class="paper-reading-list">
                    <li>배포 중심 해커톤(디플로이톤) 기획 및 총괄 운영.</li>
                    <li>지원자 100명 (정원 80명 대비 125% 달성, 모집 9시간 조기 마감).</li>
                    <li>1차 아이디어톤 + 2차 시연·발표, 2일간 진행.</li>
                    <li>현직 개발자 멘토단 직접 섭외 : 쿠팡이츠, 토스, SCOUT, FLOW, 젠다이브(Gendive).</li>
                    <li>인천대학교총장상, 정보기술대학장상, AI빅데이터센터장상 등 각 기관장께 직접 시상 요청.</li>
                </ul>
            </details>
            <ul class="item-list">
                <li>
                    <div>
                        <div class="item-title"><a href="https://res-q-theta.vercel.app/" target="_blank">ResQ</a> &mdash; 응급 의료 연결 시스템</div>
                        <div class="item-desc">구급차 뺑뺑이 문제 해결을 위한 AI 기반 병원-구급차 자동 매칭 시스템.<br>환자 상태 AI 분석, 최적 병원 추천, 실시간 이송 요청 관리.</div>
                    </div>
                </li>
                <li>
                    <div>
                        <div class="item-title"><a href="https://scam-shield-navy.vercel.app/" target="_blank">Scam Shield</a> &mdash; 피싱·스캠 예방 학습 플랫폼</div>
                        <div class="item-desc">피싱 및 스캠 수법을 시뮬레이션하여 사용자가 직접 체험하며 예방법을 학습하는 사이트.</div>
                    </div>
                </li>
            </ul>
        </section>

        <!-- 장학 -->
        <section>
            <h2>장학</h2>
            <ul class="item-list">
                <li>
                    <div>
                        <div class="item-title"><a href="scholarship.pdf" target="_blank">장학금 수혜확인서</a></div>
                        <div class="item-desc">인천대학교 장학금 수혜 내역</div>
                    </div>
                </li>
            </ul>
        </section>

        <!-- 창업 -->
        <section>
            <h2>창업</h2>
            <ul class="item-list">
                <li>
                    <div>
                        <div class="item-title">파이토치 &mdash; 대표</div>
                        <div class="item-desc"><a href="business-registration.pdf" target="_blank">사업자등록증</a></div>
                    </div>
                    <div class="item-year">2025.12</div>
                </li>
            </ul>
            <details>
                <summary>사업 개요</summary>
                <ul class="paper-reading-list">
                    <li>AI Agent 연구 및 솔루션 개발.</li>
                    <li>인천대학교 창업장학금 수혜 및 창업공용공간(DREAM IN PORT) 입주.</li>
                </ul>
            </details>
        </section>

        <!-- 병역 -->
        <section>
            <h2>병역</h2>
            <ul class="item-list">
                <li>
                    <div>
                        <div class="item-title">대한민국 공군</div>
                        <div class="item-desc">전산병 (정보체계병) 복무</div>
                    </div>
                    <div class="item-year">2021.05 &ndash; 2023.02</div>
                </li>
            </ul>
        </section>

        <footer>
            &copy; 2026 이도형. 최종 업데이트: 2026년 2월.
        </footer>
    </div>
</body>
</html>
